{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f573045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d2a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.), tensor([4, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1., 6.)\n",
    "k = 2\n",
    "\n",
    "torch.topk(a, k).values, torch.topk(a, k).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa7c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(a, k).values[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3d9e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.topk(a, k).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75fe462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(torch.topk(a, k).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d161c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7409, 0.2033, 0.9909, 0.8236],\n",
       "         [0.6404, 0.8165, 0.2285, 0.9542],\n",
       "         [0.4167, 0.3685, 0.7415, 0.8287],\n",
       "         [0.2220, 0.5589, 0.2310, 0.0971],\n",
       "         [0.9943, 0.9097, 0.1291, 0.8356]],\n",
       "\n",
       "        [[0.8047, 0.3422, 0.8618, 0.5717],\n",
       "         [0.2022, 0.6414, 0.4011, 0.2690],\n",
       "         [0.6357, 0.6724, 0.6700, 0.8491],\n",
       "         [0.8685, 0.1948, 0.9003, 0.2837],\n",
       "         [0.8013, 0.1548, 0.8626, 0.0168]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(((2, 5, 4)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fd73fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 2]), torch.Size([2, 5, 2]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a,2,-1).values.shape, torch.topk(a,2,-1).indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f46b907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 3],\n",
       "         [3, 1],\n",
       "         [3, 2],\n",
       "         [1, 2],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[2, 0],\n",
       "         [1, 2],\n",
       "         [3, 1],\n",
       "         [2, 0],\n",
       "         [2, 0]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.topk(a,2,-1).indices\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47a23ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5461, 0.4539],\n",
       "         [0.5389, 0.4611],\n",
       "         [0.5278, 0.4722],\n",
       "         [0.7075, 0.2925],\n",
       "         [0.5222, 0.4778]],\n",
       "\n",
       "        [[0.5171, 0.4829],\n",
       "         [0.6153, 0.3847],\n",
       "         [0.5581, 0.4419],\n",
       "         [0.5090, 0.4910],\n",
       "         [0.5184, 0.4816]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a,2,-1).values / torch.sum(torch.topk(a,2,-1).values, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5b0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 7],\n",
       "         [0, 2],\n",
       "         [6, 3],\n",
       "         [7, 4],\n",
       "         [0, 2],\n",
       "         [2, 5],\n",
       "         [4, 0],\n",
       "         [4, 1],\n",
       "         [2, 6],\n",
       "         [0, 7]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a,2,-1).indices[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88f40a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 1],\n",
       "         [6, 3],\n",
       "         [5, 7]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randint(10,(1, 3, 2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5697f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9, 3],\n",
       "         [0, 5],\n",
       "         [7, 1]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.randint(10,(1, 3, 2))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46cd63c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (list, dim=int, keepdim=bool), but expected one of:\n * (Tensor input, *, torch.dtype dtype = None)\n      didn't match because some of the keywords were incorrect: dim, keepdim\n * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: sum() received an invalid combination of arguments - got (list, dim=int, keepdim=bool), but expected one of:\n * (Tensor input, *, torch.dtype dtype = None)\n      didn't match because some of the keywords were incorrect: dim, keepdim\n * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "torch.sum([a,b], dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b3896b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model: int = 256\n",
    "hidden_dim: int = 512\n",
    "n_layers: int = 4\n",
    "n_heads: int = 4\n",
    "vocab_size: int = 10_000\n",
    "\n",
    "num_experts: int = 8\n",
    "num_shared_experts: int = 1\n",
    "top_k: int = 2\n",
    "\n",
    "n_kv_heads: int = 2\n",
    "max_seq_len: int =  1024\n",
    "rope_theta: float = 10_000.0\n",
    "\n",
    "dk = d_model // n_heads\n",
    "\n",
    "pairs = torch.arange(0, dk/2)\n",
    "frequencies = 1/rope_theta**(2 * pairs / dk)\n",
    "\n",
    "positions = torch.arange(max_seq_len, dtype=torch.float32)\n",
    "\n",
    "angles = positions.view(len(positions), 1).contiguous() @ frequencies.view(1, len(frequencies)).contiguous()\n",
    "\n",
    "angles = angles.repeat_interleave(2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db3f44f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7409, 0.2033, 0.9909, 0.8236],\n",
       "         [0.6404, 0.8165, 0.2285, 0.9542],\n",
       "         [0.4167, 0.3685, 0.7415, 0.8287],\n",
       "         [0.2220, 0.5589, 0.2310, 0.0971],\n",
       "         [0.9943, 0.9097, 0.1291, 0.8356]],\n",
       "\n",
       "        [[0.7409, 0.2033, 0.9909, 0.8236],\n",
       "         [0.6404, 0.8165, 0.2285, 0.9542],\n",
       "         [0.4167, 0.3685, 0.7415, 0.8287],\n",
       "         [0.2220, 0.5589, 0.2310, 0.0971],\n",
       "         [0.9943, 0.9097, 0.1291, 0.8356]],\n",
       "\n",
       "        [[0.8047, 0.3422, 0.8618, 0.5717],\n",
       "         [0.2022, 0.6414, 0.4011, 0.2690],\n",
       "         [0.6357, 0.6724, 0.6700, 0.8491],\n",
       "         [0.8685, 0.1948, 0.9003, 0.2837],\n",
       "         [0.8013, 0.1548, 0.8626, 0.0168]],\n",
       "\n",
       "        [[0.8047, 0.3422, 0.8618, 0.5717],\n",
       "         [0.2022, 0.6414, 0.4011, 0.2690],\n",
       "         [0.6357, 0.6724, 0.6700, 0.8491],\n",
       "         [0.8685, 0.1948, 0.9003, 0.2837],\n",
       "         [0.8013, 0.1548, 0.8626, 0.0168]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat_interleave(2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc096330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 7.4989e-01,  ..., 1.7783e-04, 1.3335e-04,\n",
       "         1.3335e-04],\n",
       "        [2.0000e+00, 2.0000e+00, 1.4998e+00,  ..., 3.5566e-04, 2.6670e-04,\n",
       "         2.6670e-04],\n",
       "        ...,\n",
       "        [1.0210e+03, 1.0210e+03, 7.6564e+02,  ..., 1.8156e-01, 1.3615e-01,\n",
       "         1.3615e-01],\n",
       "        [1.0220e+03, 1.0220e+03, 7.6639e+02,  ..., 1.8174e-01, 1.3629e-01,\n",
       "         1.3629e-01],\n",
       "        [1.0230e+03, 1.0230e+03, 7.6714e+02,  ..., 1.8192e-01, 1.3642e-01,\n",
       "         1.3642e-01]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cdca24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10, (10, 2))\n",
    "b = torch.randint(10, (10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e1e3a644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [9, 1],\n",
       "        [7, 4],\n",
       "        [2, 3],\n",
       "        [8, 7],\n",
       "        [0, 3],\n",
       "        [3, 7],\n",
       "        [6, 5],\n",
       "        [5, 2],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3bc2d215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 9],\n",
       "        [8, 3],\n",
       "        [9, 5],\n",
       "        [0, 8],\n",
       "        [1, 4],\n",
       "        [6, 6],\n",
       "        [4, 5],\n",
       "        [5, 5],\n",
       "        [1, 9],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2305222",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, ind = torch.where(a==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c23bcc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 8, 9]), tensor([0, 1, 0]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f23483b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [9],\n",
       "        [2]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[row,ind].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "784924a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Transformer\n",
    "from src.config import ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1e7db6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized. Params: 335168\n",
      "All Assertions Passed\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(\n",
    "    d_model=64,           \n",
    "    hidden_dim=128,       \n",
    "    n_layers=2,         \n",
    "    n_heads=4,       \n",
    "    n_kv_heads=2,        \n",
    "    vocab_size=1000, \n",
    "    max_seq_len=128,  \n",
    "    num_experts=4,  \n",
    "    num_shared_experts=1,\n",
    "    top_k=2,\n",
    "    batch_size=2 \n",
    ")\n",
    "\n",
    "model = Transformer(args)\n",
    "model.eval() \n",
    "print(\"Model Initialized. Params:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "curr_seq_len = 20\n",
    "x = torch.randint(args.vocab_size, (args.batch_size, curr_seq_len))\n",
    "\n",
    "op, router_logits = model(x)\n",
    "\n",
    "\n",
    "assert len(router_logits) == args.n_layers\n",
    "assert router_logits[0].size() == (args.batch_size,curr_seq_len,args.num_experts)\n",
    "assert op.size() == (args.batch_size, curr_seq_len, args.vocab_size)\n",
    "\n",
    "print(\"All Assertions Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6bb1a3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 1e-5\n",
    "\n",
    "torch.manual_seed(42)\n",
    "op1 = model.generate(x, max_new_tokens = 10, temperature = temp, use_kv_cache = True)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "op2 = model.generate(x, max_new_tokens = 10, temperature = temp, use_kv_cache = False)\n",
    "\n",
    "\n",
    "torch.equal(op1, op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f30a7f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[127, 815, 810, 585, 805,   2, 232, 677,  77, 335, 395, 110, 129, 940,\n",
       "         789, 790, 242, 317, 569, 696, 955, 110, 730, 344, 776, 315, 514, 392,\n",
       "         652, 337],\n",
       "        [263,  87, 197, 629, 836, 129, 617, 369, 698, 816, 370, 404, 948, 767,\n",
       "         124, 861,  61, 727, 677, 962, 932, 703, 663, 318,  24, 968,  27, 455,\n",
       "         663,  47]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "dffadeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[127, 815, 810, 585, 805,   2, 232, 677,  77, 335, 395, 110, 129, 940,\n",
       "         789, 790, 242, 317, 569, 696, 955, 110, 730, 344, 776, 315, 514, 392,\n",
       "         652, 337],\n",
       "        [263,  87, 197, 629, 836, 129, 617, 369, 698, 816, 370, 404, 948, 767,\n",
       "         124, 861,  61, 727, 677, 962, 932, 703, 663, 318,  24, 968,  27, 455,\n",
       "         663,  47]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3ec9ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Logit Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a dummy input\n",
    "x_test = torch.randint(0, 1000, (1, 20)) # Batch 1, Seq 20\n",
    "\n",
    "# 2. Run Forward with Cache=False (The \"Ground Truth\")\n",
    "logits_slow, _ = model(x_test, use_kv_cache=False)\n",
    "\n",
    "# 3. Run Forward with Cache=True (The \"Suspect\")\n",
    "# Note: We manually clear cache first just in case\n",
    "model.layers[0].attention.k_cache.zero_()\n",
    "model.layers[0].attention.v_cache.zero_()\n",
    "logits_fast, _ = model(x_test, use_kv_cache=True)\n",
    "\n",
    "# 4. Measure the difference\n",
    "diff = (logits_slow - logits_fast).abs().max().item()\n",
    "print(f\"Max Logit Difference: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "97504a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Layer Diff: 0.0\n",
      "SUCCESS: Your Logic is Correct. The 8.24 diff is just MoE Router chaos.\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input (Batch 1, Seq 20)\n",
    "x_test = torch.randint(0, 1000, (1, 20))\n",
    "\n",
    "# 1. Run Slow Mode (Capture Layer 0 Attention Output)\n",
    "model.zero_grad()\n",
    "for layer in model.layers:\n",
    "    layer.attention.k_cache.zero_()\n",
    "    layer.attention.v_cache.zero_()\n",
    "\n",
    "# Hook to capture output\n",
    "slow_attn_out = []\n",
    "def hook_slow(module, input, output):\n",
    "    slow_attn_out.append(output)\n",
    "\n",
    "# Register hook on Layer 0 Attention\n",
    "handle = model.layers[0].attention.register_forward_hook(hook_slow)\n",
    "logits_slow, _ = model(x_test, use_kv_cache=False)\n",
    "handle.remove()\n",
    "\n",
    "# 2. Run Fast Mode (Capture Layer 0 Attention Output)\n",
    "# Force prefill logic by just running it once with use_kv_cache=True\n",
    "model.zero_grad()\n",
    "for layer in model.layers:\n",
    "    layer.attention.k_cache.zero_()\n",
    "    layer.attention.v_cache.zero_()\n",
    "\n",
    "fast_attn_out = []\n",
    "def hook_fast(module, input, output):\n",
    "    fast_attn_out.append(output)\n",
    "\n",
    "handle = model.layers[0].attention.register_forward_hook(hook_fast)\n",
    "logits_fast, _ = model(x_test, use_kv_cache=True)\n",
    "handle.remove()\n",
    "\n",
    "# 3. Compare\n",
    "diff = (slow_attn_out[0] - fast_attn_out[0]).abs().max().item()\n",
    "print(f\"Attention Layer Diff: {diff}\")\n",
    "\n",
    "if diff < 1e-4:\n",
    "    print(\"SUCCESS: Your Logic is Correct. The 8.24 diff is just MoE Router chaos.\")\n",
    "else:\n",
    "    print(\"FAILURE: Your KV Cache Logic has a bug.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2a8e0bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: max|diff| = 3.8743019104003906e-07\n",
      "step 1: max|diff| = 4.4330954551696777e-07\n",
      "step 2: max|diff| = 4.6193599700927734e-07\n",
      "step 3: max|diff| = 3.5762786865234375e-07\n",
      "step 4: max|diff| = 2.980232238769531e-07\n",
      "step 5: max|diff| = 2.980232238769531e-07\n",
      "step 6: max|diff| = 4.76837158203125e-07\n",
      "step 7: max|diff| = 4.0978193283081055e-07\n",
      "step 8: max|diff| = 3.5762786865234375e-07\n",
      "step 9: max|diff| = 3.8370490074157715e-07\n",
      "KV-cache logits match.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def reset_kv_cache(model):\n",
    "    for layer in model.layers:\n",
    "        layer.attention.k_cache.zero_()\n",
    "        layer.attention.v_cache.zero_()\n",
    "\n",
    "@torch.no_grad()\n",
    "def kv_cache_logit_check(model, vocab_size=1000, prompt_len=20, max_new=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    x = torch.randint(0, vocab_size, (1, prompt_len), device=device)\n",
    "\n",
    "    # Prefill cache with full prompt (fast path)\n",
    "    reset_kv_cache(model)\n",
    "    _ = model(x, start_posn=0, use_kv_cache=True)\n",
    "\n",
    "    for t in range(max_new):\n",
    "        # Slow: full context logits for next token\n",
    "        slow_logits, _ = model(x, start_posn=0, use_kv_cache=False)\n",
    "        slow_next = slow_logits[:, -1, :]\n",
    "\n",
    "        # Fast: cached incremental logits for next token (feed last token only)\n",
    "        start_posn = x.shape[1] - 1\n",
    "        fast_logits, _ = model(x[:, -1:], start_posn=start_posn, use_kv_cache=True)\n",
    "        fast_next = fast_logits[:, -1, :]\n",
    "\n",
    "        diff = (slow_next - fast_next).abs().max().item()\n",
    "        print(f\"step {t}: max|diff| = {diff}\")\n",
    "\n",
    "        assert torch.allclose(slow_next, fast_next, rtol=1e-4, atol=1e-4), \"KV-cache mismatch\"\n",
    "\n",
    "        # Deterministic extension (greedy)\n",
    "        x = torch.cat([x, slow_next.argmax(dim=-1, keepdim=True)], dim=1)\n",
    "\n",
    "    print(\"KV-cache logits match.\")\n",
    "\n",
    "# usage\n",
    "kv_cache_logit_check(model, vocab_size=args.vocab_size, prompt_len=20, max_new=10, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "df499d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefill max diff: 0.0\n",
      "decode 1-step max diff: 3.8743019104003906e-07\n",
      "layerwise prefill attention diffs: [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def zero_all_caches(model):\n",
    "    for layer in model.layers:\n",
    "        layer.attention.k_cache.zero_()\n",
    "        layer.attention.v_cache.zero_()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_prefill(model, x):\n",
    "    # Compare full forward (no cache) vs full forward (cache prefill)\n",
    "    model.eval()\n",
    "    zero_all_caches(model)\n",
    "    y_slow, _ = model(x, start_posn=0, use_kv_cache=False)\n",
    "\n",
    "    zero_all_caches(model)\n",
    "    y_fast, _ = model(x, start_posn=0, use_kv_cache=True)\n",
    "\n",
    "    return (y_slow - y_fast).abs().max().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_decode_one_step(model, x):\n",
    "    # Prefill cache once, then compare next-token logits slow vs fast for ONE step.\n",
    "    model.eval()\n",
    "    zero_all_caches(model)\n",
    "\n",
    "    # prefill cache\n",
    "    _ = model(x, start_posn=0, use_kv_cache=True)\n",
    "\n",
    "    # slow next-token logits (full context)\n",
    "    slow, _ = model(x, start_posn=0, use_kv_cache=False)\n",
    "    slow_next = slow[:, -1, :]\n",
    "\n",
    "    # fast next-token logits (last token only)\n",
    "    start_posn = x.shape[1] - 1\n",
    "    fast, _ = model(x[:, -1:], start_posn=start_posn, use_kv_cache=True)\n",
    "    fast_next = fast[:, -1, :]\n",
    "\n",
    "    return (slow_next - fast_next).abs().max().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def layerwise_prefill_attention_diff(model, x):\n",
    "    # Finds which layerâ€™s ATTENTION output diverges on prefill\n",
    "    model.eval()\n",
    "    diffs = []\n",
    "\n",
    "    # run no-cache, capture per-layer attention outputs\n",
    "    zero_all_caches(model)\n",
    "    h = model.token_embeddings(x)\n",
    "    slow_attn_out = []\n",
    "    for layer in model.layers:\n",
    "        a = layer.attention(layer.attention_norm(h), start_posn=0, use_kv_cache=False)\n",
    "        slow_attn_out.append(a)\n",
    "        h = h + a\n",
    "        h = h + layer.feed_forward(layer.ff_norm(h))[0]\n",
    "\n",
    "    # run cache-prefill, capture per-layer attention outputs\n",
    "    zero_all_caches(model)\n",
    "    h = model.token_embeddings(x)\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        a = layer.attention(layer.attention_norm(h), start_posn=0, use_kv_cache=True)\n",
    "        diff = (slow_attn_out[i] - a).abs().max().item()\n",
    "        diffs.append(diff)\n",
    "        h = h + a\n",
    "        h = h + layer.feed_forward(layer.ff_norm(h))[0]\n",
    "\n",
    "    return diffs\n",
    "\n",
    "# ---- run ----\n",
    "x = torch.randint(0, args.vocab_size, (1, 20))\n",
    "print(\"prefill max diff:\", compare_prefill(model, x))\n",
    "print(\"decode 1-step max diff:\", compare_decode_one_step(model, x))\n",
    "print(\"layerwise prefill attention diffs:\", layerwise_prefill_attention_diff(model, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783453c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
